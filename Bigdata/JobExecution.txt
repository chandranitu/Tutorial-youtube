cd hadoop-3.2.0/bin
hadoop-mapreduce-examples-3.2.2.jar

export HADOOP_EXAMPLES=/usr/local/hadoop-3.2.2/share/hadoop/mapreduce

$HADOOP_HOME/bin/hadoop jar $HADOOP_EXAMPLES/hadoop-mapreduce-examples-3.2.2.jar pi 16 1000     #To run the pi example with 16 maps and 100000 samples, run the following command:

hadoop jar hadoop-mapreduce-examples-3.2.2.jar pi 16 1000

--------------------------------------

hadoop org.apache.hadoop.examples.pi.DistBbp 1,000,000,000,000,056 20 1000 x 500 /test/output

https://hadoop.apache.org/docs/r3.2.0/api/org/apache/hadoop/examples/pi/package-summary.html

aggregatewordcount: An Aggregate-based map/reduce program that counts the words in the input files.
aggregatewordhist: An Aggregate-based map/reduce program that computes the histogram of the words in the input files.
bbp: A map/reduce program that uses Bailey-Borwein-Plouffe to compute the exact digits of pi.
dbcount: An example job that counts the pageview counts from a database.
distbbp: A map/reduce program that uses a BBP-type formula to compute the exact bits of pi.
grep: A map/reduce program that counts the matches to a regex in the input.
join: A job that effects a join over sorted, equally partitioned data sets.
multifilewc: A job that counts words from several files.
pentomino: A map/reduce tile laying program to find solutions to pentomino problems.
pi: A map/reduce program that estimates pi using a quasi-Monte Carlo method.
randomtextwriter: A map/reduce program that writes 10 GB of random textual data per node.
randomwriter: A map/reduce program that writes 10 GB of random data per node.
secondarysort: An example defining a secondary sort to the reduce.
sort: A map/reduce program that sorts the data written by the random writer.
sudoku: A Sudoku solver.
teragen: Generate data for the terasort.
terasort: Run the terasort.
teravalidate: Check the results of the terasort.
wordcount: A map/reduce program that counts the words in the input files.
wordmean: A map/reduce program that counts the average length of the words in the input files.
wordmedian: A map/reduce program that counts the median length of the words in the input files.
wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.
